{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ea3dc9-c8ef-4ac4-9cae-181273617725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31fb304-4520-4f35-ac42-ce79df89e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O valor da variável PATH_ROOT é: /code/python/\n",
      "Diretório de trabalho atual é Y:\\code\\python\n"
     ]
    }
   ],
   "source": [
    "import path\n",
    "path.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436b6910-5296-489b-bccb-c8495b186e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = 'windows_1252'\n",
    "ANO_ENEM = 2023\n",
    "ANO_ENEM = str(ANO_ENEM)\n",
    "PATH_ENEM = r'Y:\\DATASOURCES\\enem'\n",
    "PATH_MD = r'{}\\microdados_enem_{}\\DADOS'.format(PATH_ENEM, ANO_ENEM)\n",
    "CSV_MD = f'{PATH_MD}\\\\MICRODADOS_ENEM_{ANO_ENEM}.csv'\n",
    "PARQUET_MD = f'{PATH_MD}\\\\MICRODADOS_ENEM_{ANO_ENEM}.parquet'\n",
    "PARQUET_SAN = f'{PATH_MD}\\\\MICRODADOS_ENEM_{ANO_ENEM}_SANITIZED.parquet'\n",
    "FEATHER_SAN = f'{PATH_MD}\\\\MICRODADOS_ENEM_{ANO_ENEM}_SANITIZED.feather'\n",
    "CSV_SAN = f'{PATH_MD}\\\\MICRODADOS_ENEM_{ANO_ENEM}_SANITIZED.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91218cd-9773-43fb-a2a9-8fbbd816d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enem = pd.read_parquet(PARQUET_SAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ddccd7-a6ab-47a2-bff9-dfb742152a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>TP_FAIXA_ETARIA</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>TP_NACIONALIDADE</th>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <th>TP_ANO_CONCLUIU</th>\n",
       "      <th>TP_ESCOLA</th>\n",
       "      <th>TP_ENSINO</th>\n",
       "      <th>...</th>\n",
       "      <th>Q016</th>\n",
       "      <th>Q017</th>\n",
       "      <th>Q018</th>\n",
       "      <th>Q019</th>\n",
       "      <th>Q020</th>\n",
       "      <th>Q021</th>\n",
       "      <th>Q022</th>\n",
       "      <th>Q023</th>\n",
       "      <th>Q024</th>\n",
       "      <th>Q025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210061103945</td>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210060214087</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210059980948</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210060801601</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210059085130</td>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_INSCRICAO  TP_FAIXA_ETARIA TP_SEXO  TP_ESTADO_CIVIL  TP_COR_RACA  \\\n",
       "0  210061103945                6       F              1.0          1.0   \n",
       "1  210060214087                2       F              1.0          3.0   \n",
       "2  210059980948                3       F              1.0          3.0   \n",
       "3  210060801601               11       M              1.0          1.0   \n",
       "4  210059085130                8       M              1.0          3.0   \n",
       "\n",
       "   TP_NACIONALIDADE  TP_ST_CONCLUSAO  TP_ANO_CONCLUIU  TP_ESCOLA  TP_ENSINO  \\\n",
       "0               1.0                1              NaN        NaN        NaN   \n",
       "1               1.0                2              NaN        2.0        1.0   \n",
       "2               1.0                2              NaN        2.0        1.0   \n",
       "3               1.0                1              8.0        NaN        NaN   \n",
       "4               1.0                1              5.0        NaN        NaN   \n",
       "\n",
       "   ...  Q016 Q017  Q018  Q019  Q020 Q021  Q022  Q023  Q024  Q025  \n",
       "0  ...     B    A     A     B     A    A     A     A     A     B  \n",
       "1  ...     A    A     A     B     A    A     D     A     A     B  \n",
       "2  ...     A    A     A     B     A    A     B     A     A     A  \n",
       "3  ...     B    A     B     C     B    A     C     A     B     B  \n",
       "4  ...     B    A     B     B     A    A     E     A     B     B  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122e2349-8da4-466d-bf51-c315a8694c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2704814 entries, 0 to 2704813\n",
      "Data columns (total 52 columns):\n",
      " #   Column                  Non-Null Count    Dtype  \n",
      "---  ------                  --------------    -----  \n",
      " 0   NU_INSCRICAO            2704814 non-null  int64  \n",
      " 1   TP_FAIXA_ETARIA         2704814 non-null  int64  \n",
      " 2   TP_SEXO                 2704814 non-null  object \n",
      " 3   TP_ESTADO_CIVIL         2599322 non-null  float64\n",
      " 4   TP_COR_RACA             2671700 non-null  float64\n",
      " 5   TP_NACIONALIDADE        2703619 non-null  float64\n",
      " 6   TP_ST_CONCLUSAO         2704814 non-null  int64  \n",
      " 7   TP_ANO_CONCLUIU         1026826 non-null  float64\n",
      " 8   TP_ESCOLA               1045732 non-null  float64\n",
      " 9   TP_ENSINO               1023616 non-null  float64\n",
      " 10  IN_TREINEIRO            2704814 non-null  int64  \n",
      " 11  SG_UF_ESC               716629 non-null   object \n",
      " 12  TP_DEPENDENCIA_ADM_ESC  716629 non-null   float64\n",
      " 13  TP_LOCALIZACAO_ESC      716629 non-null   float64\n",
      " 14  TP_SIT_FUNC_ESC         716629 non-null   float64\n",
      " 15  SG_UF_PROVA             2704814 non-null  object \n",
      " 16  NU_NOTA_CN              2585115 non-null  float64\n",
      " 17  NU_NOTA_CH              2704814 non-null  float64\n",
      " 18  NU_NOTA_LC              2704814 non-null  float64\n",
      " 19  NU_NOTA_MT              2585115 non-null  float64\n",
      " 20  TP_LINGUA               2704814 non-null  int64  \n",
      " 21  NU_NOTA_COMP1           2704814 non-null  float64\n",
      " 22  NU_NOTA_COMP2           2704814 non-null  float64\n",
      " 23  NU_NOTA_COMP3           2704814 non-null  float64\n",
      " 24  NU_NOTA_COMP4           2704814 non-null  float64\n",
      " 25  NU_NOTA_COMP5           2704814 non-null  float64\n",
      " 26  NU_NOTA_REDACAO         2704814 non-null  float64\n",
      " 27  Q001                    2454836 non-null  object \n",
      " 28  Q002                    2628957 non-null  object \n",
      " 29  Q003                    2383267 non-null  object \n",
      " 30  Q004                    2473005 non-null  object \n",
      " 31  Q005                    2704814 non-null  int64  \n",
      " 32  Q006                    2704814 non-null  object \n",
      " 33  Q007                    2704814 non-null  object \n",
      " 34  Q008                    2704814 non-null  object \n",
      " 35  Q009                    2704814 non-null  object \n",
      " 36  Q010                    2704814 non-null  object \n",
      " 37  Q011                    2704814 non-null  object \n",
      " 38  Q012                    2704814 non-null  object \n",
      " 39  Q013                    2704814 non-null  object \n",
      " 40  Q014                    2704814 non-null  object \n",
      " 41  Q015                    2704814 non-null  object \n",
      " 42  Q016                    2704814 non-null  object \n",
      " 43  Q017                    2704814 non-null  object \n",
      " 44  Q018                    2704814 non-null  object \n",
      " 45  Q019                    2704814 non-null  object \n",
      " 46  Q020                    2704814 non-null  object \n",
      " 47  Q021                    2704814 non-null  object \n",
      " 48  Q022                    2704814 non-null  object \n",
      " 49  Q023                    2704814 non-null  object \n",
      " 50  Q024                    2704814 non-null  object \n",
      " 51  Q025                    2704814 non-null  object \n",
      "dtypes: float64(19), int64(6), object(27)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df_enem.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49998851-20b9-4cc7-935d-4c22e07a6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar variáveis categóricas e contínuas (exemplo simplificado)\n",
    "# categoricas = df_enem.select_dtypes(include=['object']).columns\n",
    "# continuas   = df_enem.select_dtypes(include=['number']).columns\n",
    "\n",
    "# print(\"Variáveis Categóricas:\", categoricas)\n",
    "# print(\"Variáveis Contínuas:\", continuas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fad9f68-9747-4866-b54d-643c2709334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022', 'Q023', 'Q024', 'Q025', 'SG_UF_ESC', 'SG_UF_PROVA', 'TP_LINGUA', 'TP_SEXO', 'IN_TREINEIRO', 'TP_ANO_CONCLUIU', 'TP_COR_RACA', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_ESCOLA', 'TP_ESTADO_CIVIL', 'TP_FAIXA_ETARIA', 'TP_LOCALIZACAO_ESC', 'TP_NACIONALIDADE', 'TP_SIT_FUNC_ESC', 'TP_ST_CONCLUSAO']\n"
     ]
    }
   ],
   "source": [
    "# Variáveis categóricas que contém texto\n",
    "cat_texto = [\n",
    "  'NO_MUNICIPIO_ESC', 'NO_MUNICIPIO_PROVA',\n",
    "  'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', \n",
    "  'Q011', 'Q012', 'Q013', 'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', \n",
    "  'Q021', 'Q022', 'Q023', 'Q024', 'Q025', \n",
    "  'SG_UF_ESC', 'SG_UF_PROVA', \n",
    "  'TP_LINGUA', \n",
    "  'TP_SEXO', \n",
    "]\n",
    "\n",
    "# Variáveis categóricas que contém números\n",
    "cat_numero = [\n",
    "  'CO_MUNICIPIO_ESC', 'CO_MUNICIPIO_PROVA', \n",
    "  'CO_PROVA_CH', 'CO_PROVA_CN', 'CO_PROVA_LC', 'CO_PROVA_MT', \n",
    "  'CO_UF_ESC', 'CO_UF_PROVA',\n",
    "  'IN_TREINEIRO', \n",
    "  # 'NU_INSCRICAO', 'NU_ANO',\n",
    "  'TP_ANO_CONCLUIU', 'TP_COR_RACA', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', 'TP_ESCOLA', 'TP_ESTADO_CIVIL', \n",
    "  'TP_FAIXA_ETARIA', 'TP_LOCALIZACAO_ESC', 'TP_NACIONALIDADE', \n",
    "  'TP_PRESENCA_CH', 'TP_PRESENCA_CN', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT',\n",
    "  'TP_SIT_FUNC_ESC', 'TP_ST_CONCLUSAO', 'TP_STATUS_REDACAO',\n",
    "]\n",
    "\n",
    "cat_vetor = [\n",
    "  'TX_GABARITO_CH', 'TX_GABARITO_CN', 'TX_GABARITO_LC', 'TX_GABARITO_MT', \n",
    "  'TX_RESPOSTAS_CH', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT'\n",
    "]\n",
    "\n",
    "categoricas = [c for c in cat_texto + cat_numero + cat_vetor if c in df_enem.columns]\n",
    "\n",
    "continuas = [\n",
    "  'NU_NOTA_CH', 'NU_NOTA_CN', \n",
    "  'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', \n",
    "  'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO',\n",
    "]\n",
    "\n",
    "print(categoricas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdc0e363-9cb5-4bdb-a448-8c012d9148cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import os\n",
    "\n",
    "# Helper function to load and preprocess data\n",
    "def load_and_preprocess_data(filepath, selected_categorical_cols, sample_frac=1.0):\n",
    "    \"\"\"\n",
    "    Carrega os dados, seleciona colunas categóricas e transforma em formato transacional.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        _, extensao = os.path.splitext(filepath)\n",
    "        if extensao == '.csv':\n",
    "            df = pd.read_csv(filepath, delimiter=';', low_memory=False)\n",
    "        elif extensao == '.parquet':\n",
    "            df = pd.read_parquet(filepath)\n",
    "          \n",
    "        print(f\"Dataset original carregado com {len(df)} linhas.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo não encontrado em {filepath}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o arquivo: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    if sample_frac < 1.0:\n",
    "        df = df.sample(frac=sample_frac, random_state=42)\n",
    "        print(f\"Amostra de {len(df)} linhas selecionada (fração: {sample_frac}).\")\n",
    "\n",
    "    # Verifica se as colunas selecionadas existem\n",
    "    missing_cols = [col for col in selected_categorical_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Aviso: As seguintes colunas selecionadas não foram encontradas no DataFrame: {missing_cols}\")\n",
    "        selected_categorical_cols = [col for col in selected_categorical_cols if col in df.columns]\n",
    "        if not selected_categorical_cols:\n",
    "            print(\"Nenhuma das colunas categóricas selecionadas está presente. Abortando.\")\n",
    "            return None, None\n",
    "        print(f\"Continuando com as colunas encontradas: {selected_categorical_cols}\")\n",
    "\n",
    "\n",
    "    df_categorical = df[selected_categorical_cols].copy()\n",
    "\n",
    "    # Tratar valores NaN como uma categoria 'MISSING' ou 'NaN_str'\n",
    "    # Isso garante que eles se tornem itens distintos.\n",
    "    for col in df_categorical.columns:\n",
    "        df_categorical[col] = df_categorical[col].fillna('MISSING').astype(str)\n",
    "\n",
    "    transactions = []\n",
    "    for index, row in df_categorical.iterrows():\n",
    "        transaction = []\n",
    "        for col_name in df_categorical.columns:\n",
    "            if row[col_name] != 'MISSING':\n",
    "                item = f\"{col_name}_{row[col_name]}\" # Formato: NOMECOLUNA_VALOR\n",
    "                transaction.append(item)\n",
    "        transactions.append(frozenset(transaction)) # Usar frozenset para itens na transação\n",
    "\n",
    "    print(f\"Número de transações processadas: {len(transactions)}\")\n",
    "    if transactions:\n",
    "        print(f\"Exemplo de transação processada: {list(transactions[0])[:5]}...\") # Mostra os 5 primeiros itens da primeira transação\n",
    "    return transactions, df_categorical.columns # Retorna também as colunas usadas para referência\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aca46e-3b34-4545-a844-b2ba6b3f9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Implementação do Algoritmo Apriori ---\n",
    "def create_C1(dataset):\n",
    "    \"\"\"Cria uma lista de itemsets candidatos de tamanho 1.\"\"\"\n",
    "    C1 = []\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    # Retorna uma lista de frozensets, cada um contendo um único item\n",
    "    return [frozenset(item) for item in C1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80078d0-0ec7-4dbb-9242-c9f3427bf937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_D(dataset, Ck, min_support):\n",
    "    \"\"\"\n",
    "    Calcula o suporte para cada candidato em Ck e retorna os\n",
    "    itemsets frequentes (Lk) e seus suportes.\n",
    "    \"\"\"\n",
    "    item_counts = defaultdict(int)\n",
    "    num_transactions = len(dataset)\n",
    "\n",
    "    for transaction in dataset:\n",
    "        for candidate in Ck:\n",
    "            if candidate.issubset(transaction):\n",
    "                item_counts[candidate] += 1\n",
    "\n",
    "    Lk = []\n",
    "    support_data = {}\n",
    "    for itemset, count in item_counts.items():\n",
    "        support = count / num_transactions\n",
    "        if support >= min_support:\n",
    "            Lk.append(itemset)\n",
    "            support_data[itemset] = support\n",
    "    return Lk, support_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7596b9-a215-4750-bc66-f1db8e199297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_gen(Lk_minus_1, k):\n",
    "    \"\"\"\n",
    "    Gera itemsets candidatos Ck de tamanho k a partir de Lk_minus_1 (itemsets frequentes de tamanho k-1).\n",
    "    Lk_minus_1 é uma lista de frozensets.\n",
    "    \"\"\"\n",
    "    Ck = []\n",
    "    len_Lk_minus_1 = len(Lk_minus_1)\n",
    "    for i in range(len_Lk_minus_1):\n",
    "        for j in range(i + 1, len_Lk_minus_1):\n",
    "            # Converte frozensets para listas ordenadas para comparar os primeiros k-2 itens\n",
    "            L1_list = sorted(list(Lk_minus_1[i]))\n",
    "            L2_list = sorted(list(Lk_minus_1[j]))\n",
    "\n",
    "            if L1_list[:k-2] == L2_list[:k-2]: # Verifica se os primeiros k-2 itens são iguais\n",
    "                candidate = Lk_minus_1[i].union(Lk_minus_1[j])\n",
    "                if len(candidate) == k: # Garante que o novo candidato tem tamanho k\n",
    "                    Ck.append(candidate)\n",
    "    # Pruning Step (Remoção de candidatos que têm subconjuntos infrequentes)\n",
    "    Ck_pruned = []\n",
    "    for candidate in Ck:\n",
    "        is_valid = True\n",
    "        for subset in combinations(candidate, k - 1):\n",
    "            if frozenset(subset) not in Lk_minus_1:\n",
    "                is_valid = False\n",
    "                break\n",
    "        if is_valid:\n",
    "            Ck_pruned.append(candidate)\n",
    "    return Ck_pruned\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834dfc1-1e53-4734-b981-9e9101b39ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(dataset, min_support):\n",
    "    \"\"\"\n",
    "    Executa o algoritmo Apriori para encontrar todos os itemsets frequentes.\n",
    "    \"\"\"\n",
    "    if not dataset:\n",
    "        print(\"Dataset de transações está vazio. Não é possível executar o Apriori.\")\n",
    "        return [], {}\n",
    "\n",
    "    C1 = create_C1(dataset)\n",
    "    print(f\"Número de candidatos C1 únicos: {len(C1)}\")\n",
    "\n",
    "    L1, support_data = scan_D(dataset, C1, min_support)\n",
    "    print(f\"Número de itemsets frequentes L1 (suporte >= {min_support}): {len(L1)}\")\n",
    "    if not L1:\n",
    "        print(\"Nenhum itemset frequente de tamanho 1 encontrado com o suporte mínimo fornecido.\")\n",
    "        return L1, support_data\n",
    "\n",
    "    L = [L1] # Lista de listas de itemsets frequentes (L[0] é L1)\n",
    "    k = 2\n",
    "    while len(L[k-2]) > 0: # L[k-2] se refere a L_{k-1}\n",
    "        print(f\"\\n--- Gerando itemsets de tamanho {k} ---\")\n",
    "        Lk_minus_1 = L[k-2]\n",
    "        Ck = apriori_gen(Lk_minus_1, k)\n",
    "        print(f\"Número de candidatos C{k} gerados (após apriori_gen): {len(Ck)}\")\n",
    "        if not Ck:\n",
    "            print(f\"Nenhum candidato C{k} gerado. Fim do algoritmo.\")\n",
    "            break\n",
    "\n",
    "        Lk, sup_k = scan_D(dataset, Ck, min_support)\n",
    "        print(f\"Número de itemsets frequentes L{k} (suporte >= {min_support}): {len(Lk)}\")\n",
    "\n",
    "        if not Lk:\n",
    "            print(f\"Nenhum itemset frequente L{k} encontrado. Fim do algoritmo.\")\n",
    "            break\n",
    "\n",
    "        support_data.update(sup_k)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "\n",
    "    all_frequent_itemsets = [itemset for sublist_Lk in L for itemset in sublist_Lk]\n",
    "    return all_frequent_itemsets, support_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7df589cc-1ae1-4c61-9d77-c0dd2c38e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1: Carregando e pré-processando os dados...\n",
      "Dataset original carregado com 2704814 linhas.\n",
      "Amostra de 540963 linhas selecionada (fração: 0.2).\n",
      "Número de transações processadas: 540963\n",
      "Exemplo de transação processada: ['Q004_D', 'Q021_B', 'Q005_4', 'Q025_B', 'Q011_A']...\n",
      "\n",
      "Passo 2: Executando o algoritmo Apriori com min_support = 0.2...\n",
      "Número de candidatos C1 únicos: 268\n",
      "Número de itemsets frequentes L1 (suporte >= 0.2): 57\n",
      "\n",
      "--- Gerando itemsets de tamanho 2 ---\n",
      "Número de candidatos C2 gerados (após apriori_gen): 1596\n",
      "Número de itemsets frequentes L2 (suporte >= 0.2): 762\n",
      "\n",
      "--- Gerando itemsets de tamanho 3 ---\n",
      "Número de candidatos C3 gerados (após apriori_gen): 5912\n",
      "Número de itemsets frequentes L3 (suporte >= 0.2): 4689\n",
      "\n",
      "--- Gerando itemsets de tamanho 4 ---\n",
      "Número de candidatos C4 gerados (após apriori_gen): 19223\n",
      "Número de itemsets frequentes L4 (suporte >= 0.2): 17176\n",
      "\n",
      "--- Gerando itemsets de tamanho 5 ---\n",
      "Número de candidatos C5 gerados (após apriori_gen): 45636\n",
      "Número de itemsets frequentes L5 (suporte >= 0.2): 42100\n",
      "\n",
      "--- Gerando itemsets de tamanho 6 ---\n",
      "Número de candidatos C6 gerados (após apriori_gen): 78036\n",
      "Número de itemsets frequentes L6 (suporte >= 0.2): 72771\n",
      "\n",
      "--- Gerando itemsets de tamanho 7 ---\n",
      "Número de candidatos C7 gerados (após apriori_gen): 96922\n",
      "Número de itemsets frequentes L7 (suporte >= 0.2): 90838\n",
      "\n",
      "--- Gerando itemsets de tamanho 8 ---\n",
      "Número de candidatos C8 gerados (após apriori_gen): 87551\n",
      "Número de itemsets frequentes L8 (suporte >= 0.2): 82230\n",
      "\n",
      "--- Gerando itemsets de tamanho 9 ---\n",
      "Número de candidatos C9 gerados (após apriori_gen): 57140\n",
      "Número de itemsets frequentes L9 (suporte >= 0.2): 53755\n",
      "\n",
      "--- Gerando itemsets de tamanho 10 ---\n",
      "Número de candidatos C10 gerados (após apriori_gen): 26082\n",
      "Número de itemsets frequentes L10 (suporte >= 0.2): 24503\n",
      "\n",
      "--- Gerando itemsets de tamanho 11 ---\n",
      "Número de candidatos C11 gerados (após apriori_gen): 7741\n",
      "Número de itemsets frequentes L11 (suporte >= 0.2): 7243\n",
      "\n",
      "--- Gerando itemsets de tamanho 12 ---\n",
      "Número de candidatos C12 gerados (após apriori_gen): 1296\n",
      "Número de itemsets frequentes L12 (suporte >= 0.2): 1212\n",
      "\n",
      "--- Gerando itemsets de tamanho 13 ---\n",
      "Número de candidatos C13 gerados (após apriori_gen): 93\n",
      "Número de itemsets frequentes L13 (suporte >= 0.2): 87\n",
      "\n",
      "--- Gerando itemsets de tamanho 14 ---\n",
      "Número de candidatos C14 gerados (após apriori_gen): 1\n",
      "Número de itemsets frequentes L14 (suporte >= 0.2): 1\n",
      "\n",
      "--- Gerando itemsets de tamanho 15 ---\n",
      "Número de candidatos C15 gerados (após apriori_gen): 0\n",
      "Nenhum candidato C15 gerado. Fim do algoritmo.\n",
      "\n",
      "--- Resultados Finais ---\n",
      "Total de itemsets frequentes encontrados: 397424\n",
      "Alguns itemsets frequentes e seus suportes (top 20 ordenados por suporte):\n",
      "Itemset: {'TP_NACIONALIDADE_1.0'}, Suporte: 0.9774\n",
      "Itemset: {'Q017_A'}, Suporte: 0.9613\n",
      "Itemset: {'Q017_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.9394\n",
      "Itemset: {'Q012_B'}, Suporte: 0.9247\n",
      "Itemset: {'Q025_B'}, Suporte: 0.9183\n",
      "Itemset: {'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.9115\n",
      "Itemset: {'Q007_A'}, Suporte: 0.9067\n",
      "Itemset: {'Q012_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.9037\n",
      "Itemset: {'Q023_A'}, Suporte: 0.8980\n",
      "Itemset: {'Q025_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8980\n",
      "Itemset: {'Q017_A', 'Q012_B'}, Suporte: 0.8966\n",
      "Itemset: {'TP_ESTADO_CIVIL_1.0', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8913\n",
      "Itemset: {'Q017_A', 'Q007_A'}, Suporte: 0.8872\n",
      "Itemset: {'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8858\n",
      "Itemset: {'Q017_A', 'Q025_B'}, Suporte: 0.8800\n",
      "Itemset: {'Q023_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8773\n",
      "Itemset: {'Q017_A', 'Q012_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8761\n",
      "Itemset: {'Q017_A', 'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.8755\n",
      "Itemset: {'Q017_A', 'Q023_A'}, Suporte: 0.8705\n",
      "Itemset: {'Q017_A', 'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8667\n",
      "\n",
      "Itemsets frequentes com 2 ou mais itens (top 10 por suporte):\n",
      "Itemset: {'Q017_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.9394\n",
      "Itemset: {'Q012_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.9037\n",
      "Itemset: {'Q025_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8980\n",
      "Itemset: {'Q017_A', 'Q012_B'}, Suporte: 0.8966\n",
      "Itemset: {'TP_ESTADO_CIVIL_1.0', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8913\n",
      "Itemset: {'Q017_A', 'Q007_A'}, Suporte: 0.8872\n",
      "Itemset: {'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8858\n",
      "Itemset: {'Q017_A', 'Q025_B'}, Suporte: 0.8800\n",
      "Itemset: {'Q023_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8773\n",
      "Itemset: {'Q017_A', 'Q012_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8761\n"
     ]
    }
   ],
   "source": [
    "# --- Execução ---\n",
    "\n",
    "# Caminho para o arquivo CSV da amostra\n",
    "#csv_file = f'{PATH_MD}/df_enem_samples_{ANO_ENEM}.csv'\n",
    "csv_file = CSV_SAN\n",
    "# Lista de colunas categóricas a serem consideradas (ajustar conforme análise)\n",
    "# É importante escolher colunas que sejam realmente categóricas e relevantes.\n",
    "# Verifique os nomes exatos das colunas no seu arquivo df_enem_samples_2023.csv\n",
    "# Exemplo (você precisará verificar os nomes corretos no seu CSV):\n",
    "categorical_columns_to_use = [\n",
    "    'TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL',\n",
    "    'TP_COR_RACA', 'TP_ST_CONCLUSAO',\n",
    "    'TP_ANO_CONCLUIU', 'TP_ESCOLA',\n",
    "    'IN_TREINEIRO', 'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC', 'TP_STATUS_REDACAO',\n",
    "    #'Q001', 'Q002', 'Q005', 'Q006', 'Q022', 'Q024', 'Q025' # Itens do questionário socioeconômico\n",
    "]\n",
    "\n",
    "# Descomente para usar todas as colunas categóricas do dataset\n",
    "categorical_columns_to_use = categoricas\n",
    "\n",
    "# Fração da amostra a ser usada (1.0 para usar todo o arquivo de amostra, < 1.0 para uma sub-amostra)\n",
    "# Para um arquivo de amostra já reduzido, 1.0 é geralmente bom.\n",
    "# Se o arquivo 'df_enem_samples_2023.csv' ainda for muito grande, reduza esta fração.\n",
    "sample_fraction = 0.2 # 1.0\n",
    "\n",
    "print(\"Passo 1: Carregando e pré-processando os dados...\")\n",
    "transactions, used_cols = load_and_preprocess_data(csv_file, categorical_columns_to_use, sample_frac=sample_fraction)\n",
    "\n",
    "if transactions:\n",
    "    # Definir o suporte mínimo\n",
    "    # Este valor é crítico. Para datasets grandes ou com muitos itens,\n",
    "    # um valor pequeno pode gerar muitos itemsets. Para amostras, pode ser um pouco maior.\n",
    "    # Ex: 0.05 significa que o itemset deve aparecer em pelo menos 5% das transações.\n",
    "    min_support_threshold = 0.2 # Ajuste este valor conforme necessário! Pode precisar ser menor.\n",
    "\n",
    "    print(f\"\\nPasso 2: Executando o algoritmo Apriori com min_support = {min_support_threshold}...\")\n",
    "    frequent_itemsets, support_data = apriori(transactions, min_support_threshold)\n",
    "\n",
    "    print(\"\\n--- Resultados Finais ---\")\n",
    "    if frequent_itemsets:\n",
    "        print(f\"Total de itemsets frequentes encontrados: {len(frequent_itemsets)}\")\n",
    "        print(\"Alguns itemsets frequentes e seus suportes (top 20 ordenados por suporte):\")\n",
    "        \n",
    "        # Ordenar por suporte para mostrar os mais frequentes\n",
    "        sorted_support_data = sorted(support_data.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "        for itemset, support in sorted_support_data[:20]: # Mostra os 20 mais frequentes\n",
    "            print(f\"Itemset: {set(itemset)}, Suporte: {support:.4f}\") # Converte para set para melhor visualização\n",
    "        \n",
    "        # Exemplo de como filtrar itemsets com mais de um item:\n",
    "        print(\"\\nItemsets frequentes com 2 ou mais itens (top 10 por suporte):\")\n",
    "        multi_item_frequent_sets = sorted(\n",
    "            [(itemset, support) for itemset, support in support_data.items() if len(itemset) >= 2],\n",
    "            key=lambda item: item[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        for itemset, support in multi_item_frequent_sets[:10]:\n",
    "             print(f\"Itemset: {set(itemset)}, Suporte: {support:.4f}\")\n",
    "    else:\n",
    "        print(\"Nenhum itemset frequente encontrado com os parâmetros fornecidos.\")\n",
    "        print(\"Tente reduzir o 'min_support_threshold' ou verificar as colunas categóricas selecionadas.\")\n",
    "else:\n",
    "    print(\"Pré-processamento dos dados falhou. Verifique o arquivo CSV e os nomes das colunas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c1e515ad-fa2c-42f7-9bf0-bb8d2984269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540963\n",
      "41\n",
      "397367\n"
     ]
    }
   ],
   "source": [
    "print(len(transactions))\n",
    "print(len(categorical_columns_to_use))\n",
    "print(len(multi_item_frequent_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f3821-ffb8-4f2b-a888-9f168300c0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42e3f467-4eb0-469b-b983-74562cbc3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVANDO O DICIONÁRIOS COM CONJUNTO DE ITENS FREQUENTE EM PICKLE\n",
    "import datetime\n",
    "import pickle\n",
    "now = datetime.datetime.now()\n",
    "pickle_filename = f'{PATH_MD}/MULTI_ITEM_FREQUENT_SETS_ENEM_{ANO_ENEM}_{str(now).split('.')[0].replace('-', '').replace(':','').replace(' ','_')}.pickle'\n",
    "with open(pickle_filename, 'wb') as file:\n",
    "  pickle.dump(multi_item_frequent_sets, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "071f6e86-feb7-43de-9a1a-8f787d1f307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Itemsets frequentes com 2 ou mais itens (top 50 por suporte):\n",
      "Itemset: {'Q017_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.9394\n",
      "Itemset: {'Q012_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.9037\n",
      "Itemset: {'Q025_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8980\n",
      "Itemset: {'Q017_A', 'Q012_B'}, Suporte: 0.8966\n",
      "Itemset: {'TP_ESTADO_CIVIL_1.0', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8913\n",
      "Itemset: {'Q017_A', 'Q007_A'}, Suporte: 0.8872\n",
      "Itemset: {'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8858\n",
      "Itemset: {'Q017_A', 'Q025_B'}, Suporte: 0.8800\n",
      "Itemset: {'Q023_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8773\n",
      "Itemset: {'Q017_A', 'Q012_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8761\n",
      "Itemset: {'Q017_A', 'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.8755\n",
      "Itemset: {'Q017_A', 'Q023_A'}, Suporte: 0.8705\n",
      "Itemset: {'Q017_A', 'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8667\n",
      "Itemset: {'Q017_A', 'Q025_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8603\n",
      "Itemset: {'Q017_A', 'TP_ESTADO_CIVIL_1.0', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8559\n",
      "Itemset: {'Q012_B', 'Q007_A'}, Suporte: 0.8538\n",
      "Itemset: {'Q025_B', 'Q012_B'}, Suporte: 0.8519\n",
      "Itemset: {'Q017_A', 'Q023_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8503\n",
      "Itemset: {'Q017_A', 'Q015_A'}, Suporte: 0.8464\n",
      "Itemset: {'TP_NACIONALIDADE_1.0', 'Q015_A'}, Suporte: 0.8451\n",
      "Itemset: {'Q012_B', 'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.8415\n",
      "Itemset: {'Q023_A', 'Q012_B'}, Suporte: 0.8388\n",
      "Itemset: {'Q020_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8386\n",
      "Itemset: {'Q025_B', 'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.8378\n",
      "Itemset: {'Q017_A', 'Q012_B', 'Q007_A'}, Suporte: 0.8374\n",
      "Itemset: {'Q017_A', 'Q020_A'}, Suporte: 0.8351\n",
      "Itemset: {'Q012_B', 'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8343\n",
      "Itemset: {'Q025_B', 'TP_NACIONALIDADE_1.0', 'Q012_B'}, Suporte: 0.8329\n",
      "Itemset: {'Q025_B', 'Q007_A'}, Suporte: 0.8279\n",
      "Itemset: {'Q017_A', 'TP_NACIONALIDADE_1.0', 'Q015_A'}, Suporte: 0.8272\n",
      "Itemset: {'Q023_A', 'Q007_A'}, Suporte: 0.8266\n",
      "Itemset: {'TP_ESTADO_CIVIL_1.0', 'Q007_A'}, Suporte: 0.8247\n",
      "Itemset: {'Q017_A', 'Q025_B', 'Q012_B'}, Suporte: 0.8241\n",
      "Itemset: {'Q012_B', 'TP_NACIONALIDADE_1.0', 'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.8228\n",
      "Itemset: {'Q025_B', 'TP_NACIONALIDADE_1.0', 'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.8196\n",
      "Itemset: {'Q023_A', 'Q012_B', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8195\n",
      "Itemset: {'Q017_A', 'Q012_B', 'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8182\n",
      "Itemset: {'Q017_A', 'Q023_A', 'Q012_B'}, Suporte: 0.8178\n",
      "Itemset: {'Q023_A', 'Q025_B'}, Suporte: 0.8174\n",
      "Itemset: {'Q023_A', 'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.8165\n",
      "Itemset: {'Q017_A', 'Q020_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8158\n",
      "Itemset: {'Q017_A', 'Q012_B', 'TP_ESTADO_CIVIL_1.0'}, Suporte: 0.8155\n",
      "Itemset: {'Q017_A', 'Q023_A', 'Q007_A'}, Suporte: 0.8114\n",
      "Itemset: {'Q012_B', 'Q015_A'}, Suporte: 0.8096\n",
      "Itemset: {'Q025_B', 'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8092\n",
      "Itemset: {'Q017_A', 'Q025_B', 'Q007_A'}, Suporte: 0.8086\n",
      "Itemset: {'Q023_A', 'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8074\n",
      "Itemset: {'Q017_A', 'TP_ESTADO_CIVIL_1.0', 'Q007_A'}, Suporte: 0.8067\n",
      "Itemset: {'TP_ESTADO_CIVIL_1.0', 'Q007_A', 'TP_NACIONALIDADE_1.0'}, Suporte: 0.8060\n",
      "Itemset: {'Q017_A', 'Q025_B', 'TP_NACIONALIDADE_1.0', 'Q012_B'}, Suporte: 0.8056\n"
     ]
    }
   ],
   "source": [
    "top = 50\n",
    "print(f\"\\nItemsets frequentes com 2 ou mais itens (top {top} por suporte):\")\n",
    "pickle_filename = 'Y:\\\\DATASOURCES\\\\enem\\\\microdados_enem_2023\\\\DADOS/MULTI_ITEM_FREQUENT_SETS_ENEM_2023_20250517_150809.pickle'\n",
    "with open(pickle_filename, 'rb') as file:\n",
    "  loaded_mifs = pickle.load(file)\n",
    "\n",
    "for itemset, support in loaded_mifs[:top]:\n",
    "     print(f\"Itemset: {set(itemset)}, Suporte: {support:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a588640-372f-4b01-b567-dcb6efa58367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y:\\\\DATASOURCES\\\\enem\\\\microdados_enem_2023\\\\DADOS/MULTI_ITEM_FREQUENT_SETS_ENEM_2023_20250517_150809.pickle'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bedd6-42e9-4d8a-852e-656b2046f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUALQUER DOS ITENS\n",
    "itens = ['TP_COR_RACA_1.0', 'TP_COR_RACA_2.0', 'TP_COR_RACA_3.0', 'TP_COR_RACA_4.0', 'TP_COR_RACA_5.0']\n",
    "pickle_filename = 'Y:\\\\DATASOURCES\\\\enem\\\\microdados_enem_2023\\\\DADOS/MULTI_ITEM_FREQUENT_SETS_ENEM_2023_20250517_150809.pickle'\n",
    "with open(pickle_filename, 'rb') as file:\n",
    "  loaded_mifs = pickle.load(file)\n",
    "\n",
    "for itemset, support in loaded_mifs:\n",
    "  if any(x for x in itens if x in itemset):\n",
    "     print(f\"Itemset: {set(itemset)}, Suporte: {support:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe17dcb-ac2c-4028-a4e5-d6cb4a2ad91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOS OS ITENS\n",
    "itens = ['TP_ESCOLA_2.0']#, 'TP_COR_RACA_2.0', 'TP_COR_RACA_3.0', 'TP_COR_RACA_4.0', 'TP_COR_RACA_5.0']\n",
    "pickle_filename = 'Y:\\\\DATASOURCES\\\\enem\\\\microdados_enem_2023\\\\DADOS/MULTI_ITEM_FREQUENT_SETS_ENEM_2023_20250517_150809.pickle'\n",
    "with open(pickle_filename, 'rb') as file:\n",
    "  loaded_mifs = pickle.load(file)\n",
    "\n",
    "for itemset, support in loaded_mifs:\n",
    "  matches = [x for x in itens if x in itemset]\n",
    "  if [x for x in matches if x in itens] == itens:\n",
    "     print(f\"Itemset: {set(itemset)}, Suporte: {support:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16c05d81-d30f-4d95-a919-57316a810234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itens_1 = ['TP_COR_RACA_1.0', 'TP_ESCOLA_2.0', 'TP_COR_RACA_2.0', 'TP_COR_RACA_3.0', 'TP_COR_RACA_4.0', 'TP_COR_RACA_5.0']\n",
    "itens_2 = ['TP_COR_RACA_1.0', 'TP_ESCOLA_2.0']#, 'TP_COR_RACA_2.0', 'TP_COR_RACA_3.0', 'TP_COR_RACA_4.0', 'TP_COR_RACA_5.0']\n",
    "[x for x in itens_2 if x in itens_1] == itens_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b54478-090e-4fa1-837f-21a9e0582d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu@py312",
   "language": "python",
   "name": "scripts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
